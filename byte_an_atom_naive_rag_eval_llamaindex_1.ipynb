{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stigsfoot/genai-free-workshops-2024/blob/main/byte_an_atom_naive_rag_eval_llamaindex_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6m1lOaUcKl5"
      },
      "source": [
        "# Retrieval Augmented Generation (RAG) with Actions (LlamaIndex Edition)\n",
        "\n",
        "In this example, we'll be taking a look at how to apply the power of **R**etrieval **A**ugmented **G**eneration (RAG) to LLMs .\n",
        "\n",
        "We'll get started by installing the prerequisite libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC-PQoCxcKl6"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "    nemoguardrails \\\n",
        "    datasets \\\n",
        "    openai \\\n",
        "    chromadb \\\n",
        "    tqdm \\\n",
        "    langchain \\\n",
        "    pandas \\\n",
        "    llama-index \\\n",
        "    llama-index-llms-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The nest_asyncio module enables the nesting of asynchronous functions within an already running async loop.\n",
        "# This is necessary because Jupyter notebooks inherently operate in an asynchronous loop.\n",
        "# By applying nest_asyncio, we can run additional async functions within this existing loop without conflicts.\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.core.node_parser import SentenceSplitter, SimpleNodeParser\n",
        "from llama_index.llms.openai import OpenAI\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "WSIzKgFXDWTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZFf3xy9pwsN"
      },
      "source": [
        "## Download Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0709sN9cKl8"
      },
      "source": [
        "To begin, we need to setup our data and retrieval components for RAG. We'll start with a dataset that contains info on the recent Llama 2 models:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/black-code-collective/'\n",
        "!curl 'https://raw.githubusercontent.com/stigsfoot/genai-free-workshops-2024/main/labs/black_code_collective.txt' -o 'data/black-code-collective/black_code_collective.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pue_xcgFDnFR",
        "outputId": "29599976-835e-4492-8ed3-e45f1ab21007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 26989  100 26989    0     0  65803      0 --:--:-- --:--:-- --:--:-- 65826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load our data/build an index"
      ],
      "metadata": {
        "id": "NT0dLImrD2pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
        "from llama_index.core import Settings\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "\n",
        "openai_api_key = userdata.get('OPENAI_KEY')\n",
        "\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "documents = SimpleDirectoryReader(\"./data/black-code-collective/\").load_data()\n",
        "\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 50\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        ")\n",
        "\n",
        "query_engine = index.as_query_engine(similarity_top_k=4)\n"
      ],
      "metadata": {
        "id": "izuvUmr5P7zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"./data/black-code-collective/\").load_data()\n",
        "\n",
        "# Define an LLM\n",
        "llm = OpenAI(model=\"gpt-4\")\n",
        "\n",
        "# Build index with a chunk_size of 512\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "HEXc8iaeD2Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question samples:\n",
        "How does the manifesto suggest improving tech recruiting for diversity?\n",
        "What changes to job descriptions does the manifesto advocate for inclusivity?\n",
        "What leadership actions are recommended to enhance workplace diversity?\n",
        "'''\n",
        "query_engine = vector_index.as_query_engine()\n",
        "response_vector = query_engine.query(\"What changes to job descriptions does the manifesto advocate for inclusivity?\")\n",
        "response_vector.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mV_DmIN2LmRW",
        "outputId": "2a831f44-9b27-40f0-d17c-6b6b89a2b72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The manifesto advocates for job descriptions to be gender-neutral and to include qualifications that accurately reflect the tasks that need to be performed. It suggests stating that candidates are not expected to know everything listed in the job description and emphasizing the organization's value for growth and the ability to learn. These changes are aimed at increasing the likelihood of diverse candidates applying.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First retrieved node\n",
        "response_vector.source_nodes[0].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "WdyymSwxNKzc",
        "outputId": "87ba564f-10be-4d86-83bb-77289f42ec3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Make sure that the job descriptions are gender-neutral and qualifications that reflect what the actual job will need to be done. Including in job descriptions that candidates are not expected to know 100% of the things listed. It should state that the organization values growth and the ability to learn. These changes will increase the likelihood of diverse candidates applying.\\n\\nABOLISH GPA REQUIREMENTS\\nStudies have also found that Grade Point Averages (GPAs) are ineffective in predicting an applicant\\'s performance on the job. GPAs create barriers for people who may not have had the economic wealth/support to maintain or even earn \"good grades\". As universities and schools become more expensive a lot of Black and Brown students have had to work more jobs outside of school to pay for their education. As they try to balance work/school GPAs tend to decrease. We challenge companies to look beyond GPAs and test these students through their skills rather than completely discarding them based on GPA.\\n\\nREFERENCES\\nhttps://www.forbes.com/sites/janicegassam/2018/12/18/5-reasons-why-the-pipeline-problem-is-just-a-myth/#5e58ed18227a\\n\\nhttps://www.fastcompany.com/90225190/4-diversity-recruiting-challenges-for-tech\\n\\nhttps://hr.fas.harvard.edu/files/fas-hr/files/recruiting_for_diversity_9.17.13_0.pdf\\n\\nhttps://www.hrdive.com/news/should-employers-care-about-gpa-anymore/528430/\\n\\nhttps://www.researchgate.net/publication/285040780_College_Grade_Point_Average_as_a_Predictor_of_Adult_Success_A_Meta-Analytic_Review_and_Some_Additional_Evidence\\n\\nINCLUSION\\nAcquiring a diverse workforce is only step one of the processes. Once you have hired the candidates, you should work to make sure these candidates feel included within your workplace. Every company will have slightly different needs, but below are some helpful ways you can make sure your Black employees feel welcome.\\n\\nIT STARTS AT THE TOP\\nLeadership should lead the charge in signaling how valued diverse voices are. This can be verbally stated, but the action is the most important part here.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second retrieved node\n",
        "response_vector.source_nodes[1].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "sdL9g-xsENhJ",
        "outputId": "d9b99679-dc5f-4b9e-d019-f91233239bb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"BLACK CODE COLLECTIVE\\n\\nBLACK LIVES MATTER\\nBLACK TECH WORKERS MATTER\\nA BLACK TECH WORKER'S MANIFESTO\\n\\nAs first-generation Black tech workers, we have excelled in positions in a field once obscured for many who look like us. However, recent events have reminded us that no matter the success we obtain personally, we still exist in a culture where our bodies threaten and make others feel uncomfortable. We refuse to let this go by unaddressed in the tech community. We do not proclaim to have all the answers. Frankly, it was exhausting for us to sit down under the weight of oppression and still muster the energy to research and write to educate others. However, when we think about why we created Black Code Collective we remember that this community has recognized and empowered our Black voices and we want to contribute to building a world where the next generation of Black and Brown tech workers have respect our ancestors deeply desired. We don't write these words to educate every white person in tech, but as a reminder to our community on what we deserve.\\n\\n-Black Code Collective Founders\\n\\nRECRUITING\\nTo hire a diverse workforce requires a lot more effort than what has currently been done in most tech companies. Recruiting diverse candidates will require a holistic and serious reform in hiring practices. Below are some of the ways we can challenge assertions that companies have made.\\n\\nTHE PIPELINE ISSUE\\nRecruiting from colleges and universities is a common practice amongst most major tech companies. One of the things we have noticed is the large difference in recruitment from “elite” universities where - because of economic and institutional racism - it is harder for Black students to attend and graduate from. One way to expand the pipeline is by recruiting and investing in hiring from Historically Black Colleges and Universities (HBCUs). Another way to expand the pipeline is to recruit through conferences and groups focused on uplifting diverse candidates like National Society of Black Engineers (NSBE).\\n\\nINCLUSIVE JOB DESCRIPTIONS\\nThe first thing a lot of candidates will be judging a company on is their job posting. Through the language provided in the job descriptions, it could cause a lot of candidates who are qualified to not even bother applying. Make sure that the job descriptions are gender-neutral and qualifications that reflect what the actual job will need to be done.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eval"
      ],
      "metadata": {
        "id": "GZEpgVEyVK9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes,\n",
        "    llm=llm,\n",
        "    num_questions_per_chunk=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Begv5CmMENfC",
        "outputId": "06f549d2-058d-4424-d8ae-1fb4c532a3d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:44<00:00,  2.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retriever"
      ],
      "metadata": {
        "id": "SoGKCeOBVSR5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_index.as_retriever(similarity_top_k=2)"
      ],
      "metadata": {
        "id": "Q6R29wXTENcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
        "    [\"mrr\", \"hit_rate\"], retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "aG6Pdq4XENXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
      ],
      "metadata": {
        "id": "N_jTmddFENVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_results(name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr]}\n",
        "    )\n",
        "\n",
        "    return metric_df\n",
        "\n",
        "# Get the list of queries from the above created dataset\n",
        "\n",
        "queries = list(qa_dataset.queries.values())"
      ],
      "metadata": {
        "id": "0HXq7nbnENQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gpt-3.5-turbo\n",
        "gpt35 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n",
        "\n",
        "# gpt-4\n",
        "gpt4 = OpenAI(temperature=0, model=\"gpt-4\")\n",
        "service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LsZ2H9mVlnZ",
        "outputId": "cad142fc-e73b-413c-e4d8-a78be0e3ab83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-8ced365f261a>:3: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context_gpt35 = ServiceContext.from_defaults(llm=gpt35)\n",
            "<ipython-input-52-8ced365f261a>:7: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
            "  service_context_gpt4 = ServiceContext.from_defaults(llm=gpt4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_index = VectorStoreIndex(nodes, service_context = service_context_gpt35)\n",
        "query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "YWVbDCNGVlkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Faithfulness checks\n",
        "\n",
        "This is a class designed to evaluate the faithfulness of a model's responses. Basically how accurately and reliably the model's responses reflect the information in the provided context or data."
      ],
      "metadata": {
        "id": "XrtXE2ngV83V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "faithfulness_gpt4 = FaithfulnessEvaluator(service_context=service_context_gpt4)\n",
        "eval_query = queries[10]\n",
        "\n",
        "eval_query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mCTGujRyVlhv",
        "outputId": "72588277-5e57-4eda-8a97-36991b5c30e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the context, what are some of the challenges faced by Black tech workers in advocating for their careers and how can organizations help combat these issues?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the model\n",
        "response_vector = query_engine.query(eval_query)\n",
        "\n",
        "# Display the generated answer in a clear and concise format\n",
        "print(\"Generated Answer:\\n\", response_vector)\n",
        "\n",
        "# Evaluate the response for faithfulness\n",
        "eval_result = faithfulness_gpt4.evaluate_response(response=response_vector)\n",
        "\n",
        "# Check and display if the response passed the faithfulness evaluation\n",
        "is_passing = eval_result.passing\n",
        "print(\"Faithfulness Evaluation Passed?\\n\", is_passing)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPHUwv9yVLtX",
        "outputId": "6831760e-63bc-47b8-9eee-ba87d6138a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Answer:\n",
            " Some of the challenges faced by Black tech workers in advocating for their careers include feeling inadequate due to Imposter Syndrome, not knowing how to ask for positions, salaries, and responsibilities they deserve, and facing unconscious bias in leadership selection processes. Organizations can combat these issues by providing coaching on how to communicate contributions effectively, offering training for management on equitable talent evaluation, ensuring diverse voices are part of promotion conversations, establishing clear paths to promotion, and creating a more inclusive workplace culture that recognizes and validates workplace racism while promoting diverse talent at all levels of the organization.\n",
            "Faithfulness Evaluation Passed:\n",
            " True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Relevancy Evaluator\n",
        "Checking if the response stays on topic, addressing the specific points raised in the question, and does not include unrelated or tangential information."
      ],
      "metadata": {
        "id": "MaNsLfRaWcnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import RelevancyEvaluator\n",
        "\n",
        "relevancy_gpt4 = RelevancyEvaluator(service_context=service_context_gpt4)\n",
        "# Pick a query\n",
        "query = queries[10]\n",
        "\n",
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "00tw7C_CWGoL",
        "outputId": "47cd23ad-1394-4f75-b023-028b9cfdca2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'According to the context, what are some of the challenges faced by Black tech workers in advocating for their careers and how can organizations help combat these issues?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate response.\n",
        "# response_vector has response and source nodes (retrieved context)\n",
        "response_vector = query_engine.query(query)\n",
        "\n",
        "# Relevancy evaluation\n",
        "eval_result = relevancy_gpt4.evaluate_response(\n",
        "    query=query, response=response_vector\n",
        ")\n",
        "\n",
        "# You can check passing parameter in eval_result if it passed the evaluation.\n",
        "eval_result.passing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4BpheogWGmL",
        "outputId": "f6c219bf-0326-4ee4-e766-c81032b4284e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the response from the query engine\n",
        "response_vector = query_engine.query(query)\n",
        "\n",
        "# Display the generated response and context for clarity\n",
        "print(\"Generated Response and Context:\\n\", response_vector)\n",
        "\n",
        "# Perform relevancy evaluation on the generated response\n",
        "eval_result = relevancy_gpt4.evaluate_response(query=query, response=response_vector)\n",
        "\n",
        "# Extract and display the outcome of the relevancy evaluation\n",
        "is_passing = eval_result.passing\n",
        "print(\"Relevancy Evaluation Passed?\\n\", is_passing)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HUbuyd4V7TG",
        "outputId": "f4ce3f7b-95f1-435a-dc03-92e791fdc644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Response and Context:\n",
            " Black tech workers face challenges in advocating for their careers due to Imposter Syndrome, lack of knowledge on how to ask for positions, salaries, and responsibilities, and feeling unsupported by their organization. Organizations can combat these issues by providing coaching on how to communicate contributions and training for management on how to evaluate talent equitably. Additionally, having clear paths to promotion and promoting diverse voices in leadership positions can help empower Black tech workers and create a more inclusive workplace culture.\n",
            "Relevancy Evaluation Passed?\n",
            " True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can get the feedback for the evaluation.\n",
        "eval_result.feedback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TVPffe3HWGju",
        "outputId": "de81a711-4510-4224-cea4-a07e0af429a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'YES'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Eval with Tonic\n"
      ],
      "metadata": {
        "id": "vKlMzkj8XmtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tonic-validate -q"
      ],
      "metadata": {
        "id": "3MC3IdhNXo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "xASUUJ2oaGrc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESJd_KjhaJp4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "redacre",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}